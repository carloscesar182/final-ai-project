# Final AI Project ğŸ¯

Projeto final do curso de InteligÃªncia Artificial, desenvolvido em Python.  
O objetivo Ã© construir um pipeline completo de **Machine Learning**, incluindo:
- PrÃ©-processamento de dados
- Treinamento de modelos customizados
- AutoML
- AvaliaÃ§Ã£o de modelos
- InterpretaÃ§Ã£o de modelos (XAI)

---

## ğŸ“‚ Estrutura do Projeto

final_ai_project/
â”‚â”€â”€ src/
â”‚ â”œâ”€â”€ data_loader.py # FunÃ§Ãµes para carregar datasets
â”‚ â”œâ”€â”€ data_preprocessing.py # FunÃ§Ãµes de limpeza, transformaÃ§Ã£o e split dos dados
â”‚ â”œâ”€â”€ custom_models.py # DefiniÃ§Ã£o de modelos customizados (ex: GradientBoostingClassifier)
â”‚ â”œâ”€â”€ automl_model.py # Pipeline de AutoML (AutoSklearn, Optuna, etc.)
â”‚ â”œâ”€â”€ model_evaluation.py # FunÃ§Ãµes para mÃ©tricas e avaliaÃ§Ã£o dos modelos
â”‚ â”œâ”€â”€ explain_model.py # InterpretaÃ§Ã£o dos modelos (SHAP, LIME, etc.)
â”‚ â””â”€â”€ main.py # Script principal para rodar o pipeline completo
â”‚
â”‚â”€â”€ tests/
â”‚ â”œâ”€â”€ test_preprocessing.py # Testes unitÃ¡rios do prÃ©-processamento
â”‚ â”œâ”€â”€ test_train_models.py # Testes de treinamento de modelos
â”‚ â”œâ”€â”€ test_evaluation.py # Testes de avaliaÃ§Ã£o
â”‚ â””â”€â”€ test_xai.py # Testes de explicabilidade
â”‚
â”‚â”€â”€ requirements.txt # DependÃªncias do projeto
â”‚â”€â”€ README.md # DocumentaÃ§Ã£o do projeto

---

## âš™ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/carloscesar182/final-ai-project.git
cd final-ai-project
```

2. Crie o ambiente virtual:
```bash
python -m venv .venv
```

3. Ative o ambiente:
- Windows:

```bash
.venv\Scripts\activate
```
- Linux/Mac:
```bash
source .venv/bin/activate
```

4. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

## ğŸš€ Como Executar
Rode o pipeline completo com:

```bash
python src/main.py
```

## ğŸ§ª Testes
Para rodar os testes unitÃ¡rios:

```bash
pytest
```

## ğŸ“Š Exemplo de Uso

Um exemplo simples de como rodar o pipeline no Python:
```python
from src.data_loader import load_dataset
from src.data_preprocessing import preprocess_data
from src.custom_models import train_custom_model
from src.model_evaluation import evaluate_model
from src.explain_model import explain_with_shap

# 3. Carregar dados (ex: dataset Titanic, Iris, etc.)
df = load_dataset("iris")

# 2. PrÃ©-processar
X_train, X_test, y_train, y_test = preprocess_data(df, target="species")

# 3. Treinar modelo
model = train_custom_model(X_train, y_train)

# 4. Avaliar
metrics = evaluate_model(model, X_test, y_test)
print("Resultados:", metrics)

# 5. Interpretar
explain_with_shap(model, X_test)
```

## ğŸ“Š Modelos
Atualmente, o projeto inclui:
- GradientBoostingClassifier (modelo base)
- AutoML para seleÃ§Ã£o e tuning de outros modelos
- InterpretaÃ§Ã£o via SHAP/LIME

## ğŸ›  Tecnologias
- Python 3.10+
- Scikit-learn
- Pandas & Numpy
- SHAP / LIME (XAI)
- Pytest (testes)
- Auto-sklearn / Optuna (AutoML)

## âœ¨ PrÃ³ximos Passos
- Adicionar novos modelos customizados
- Melhorar explicabilidade com grÃ¡ficos interativos
- Deploy em API/Streamlit